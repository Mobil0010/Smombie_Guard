import cv2
import mediapipe as mp
import numpy as np
from tensorflow.keras.models import load_model
from ultralytics import YOLO
import winsound
import time

# ==========================================
# 1. ëª¨ë¸ ë° ì„¤ì • ë¡œë”©
# ==========================================
# (1) YOLO ëª¨ë¸ (ë¬¼ì²´ ì¸ì‹)
print("ğŸš€ YOLO ëª¨ë¸ ë¡œë”© ì¤‘...")
yolo_model = YOLO('yolov8m.pt')
# 0:ì‚¬ëŒ, 65:ë¦¬ëª¨ì»¨, 67:í°, 73:ì±…
target_classes = [0, 65, 67, 73] 

# (2) LSTM ëª¨ë¸ (í–‰ë™ ì¸ì‹)
print("ğŸ§  LSTM ëª¨ë¸ ë¡œë”© ì¤‘...")
lstm_model = load_model('smombie_model.h5')
actions = ['normal', 'smombie']
seq_length = 30
seq = []

# (3) MediaPipe (ìì„¸ ì¶”ì •)
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5)

# (4) ê¸°íƒ€ ë³€ìˆ˜
last_beep_time = 0

# ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜ (ì†ì´ ë°•ìŠ¤ ì•ˆì— ìˆëŠ”ì§€)
def is_inside_box(x, y, box):
    x1, y1, x2, y2 = box
    margin = 50 # ì†ì´ ì‚´ì§ ë²—ì–´ë‚˜ë„ ì¸ì •
    return (x1 - margin) < x < (x2 + margin) and (y1 - margin) < y < (y2 + margin)

# ==========================================
# 2. ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==========================================
cap = cv2.VideoCapture(0)

print("âœ… ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ ê°€ë™! (YOLO + LSTM)")
print("ğŸ‘‰ ì¡°ê±´: [ì†ì— í° ìˆìŒ] AND [ìŠ¤ëª¸ë¹„ ìì„¸] -> ê²½ê³ !")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ---------------------------------------------
    # Step A: MediaPipeë¡œ ë¼ˆëŒ€ ì¶”ì¶œ (LSTMìš©)
    # ---------------------------------------------
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(img)
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    
    # ê¸°ë³¸ ë³€ìˆ˜ ì´ˆê¸°í™”
    is_holding_phone = False
    action = "analyzing..."
    lstm_conf = 0.0

    if result.pose_landmarks:
        # 1. ë¼ˆëŒ€ ê·¸ë¦¬ê¸°
        mp_drawing.draw_landmarks(img, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        
        # 2. LSTM ë°ì´í„° ì „ì²˜ë¦¬
        joint = np.zeros((33, 4))
        for j, lm in enumerate(result.pose_landmarks.landmark):
            joint[j] = [lm.x, lm.y, lm.z, lm.visibility]
        
        d = joint.flatten()
        seq.append(d)
        if len(seq) > seq_length:
            seq.pop(0)

        # 3. ì£¼ìš” ê´€ì ˆ ì¢Œí‘œ (YOLOì™€ ë§¤ì¹­ìš©)
        h, w, _ = img.shape
        landmarks = result.pose_landmarks.landmark
        left_wrist = (int(landmarks[15].x * w), int(landmarks[15].y * h))
        right_wrist = (int(landmarks[16].x * w), int(landmarks[16].y * h))
        
        # ---------------------------------------------
        # Step B: YOLOë¡œ ë¬¼ì²´ ê°ì§€ (í° ìˆëŠ”ì§€?)
        # ---------------------------------------------
        # confë¥¼ ì¢€ ë‚®ì¶°ì„œ(0.3) í° ë’·ë©´ë„ ì˜ ì¡ê²Œ í•¨
        yolo_results = yolo_model(frame, classes=target_classes, conf=0.3, verbose=False)
        
        for r in yolo_results:
            for box in r.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cls = int(box.cls[0])
                
                # ì‚¬ëŒì´ ì•„ë‹ˆë©´(í°, ë¦¬ëª¨ì»¨, ì±…) ë°•ìŠ¤ ê²€ì‚¬
                if cls != 0: 
                    # ì‹œê°í™” (íšŒìƒ‰ ë°•ìŠ¤)
                    cv2.rectangle(img, (x1, y1), (x2, y2), (150, 150, 150), 1)
                    
                    # ì†ëª©ì´ ì´ ë°•ìŠ¤ ê·¼ì²˜ì— ìˆëŠ”ì§€ í™•ì¸!
                    held_by_left = is_inside_box(left_wrist[0], left_wrist[1], [x1, y1, x2, y2])
                    held_by_right = is_inside_box(right_wrist[0], right_wrist[1], [x1, y1, x2, y2])
                    
                    if held_by_left or held_by_right:
                        is_holding_phone = True
                        # ê°ì§€ëœ í°ì€ ë¹¨ê°„ ë°•ìŠ¤ë¡œ ê°•ì¡°
                        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
                        cv2.putText(img, "PHONE FOUND", (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)

        # ---------------------------------------------
        # Step C: LSTM í–‰ë™ ì˜ˆì¸¡ (ìŠ¤ëª¸ë¹„ ìì„¸ì¸ì§€?)
        # ---------------------------------------------
        if len(seq) == seq_length:
            input_data = np.expand_dims(np.array(seq), axis=0)
            y_pred = lstm_model.predict(input_data, verbose=0).squeeze()
            i_pred = int(np.argmax(y_pred))
            lstm_conf = y_pred[i_pred]
            
            if lstm_conf > 0.6: # í™•ì‹ ë„ 60% ì´ìƒì¼ ë•Œë§Œ ê°±ì‹ 
                action = actions[i_pred]

    # ---------------------------------------------
    # Step D: ìµœì¢… íŒë‹¨ (AND ì¡°ê±´)
    # ---------------------------------------------
    # 1. LSTMì´ 'smombie'ë¼ê³  íŒë‹¨í–ˆê³ 
    # 2. YOLOê°€ 'ì†ì— í°ì´ ìˆë‹¤'ê³  íŒë‹¨í–ˆì„ ë•Œ
    
    status_color = (0, 255, 0) # í‰í™”ë¡œì›€ (ì´ˆë¡)
    final_decision = "SAFE"

    if action == 'smombie':
        if is_holding_phone:
            # ğŸš¨ ì§„ì§œ ìœ„í—˜ ìƒí™©!
            final_decision = "DANGER: SMOMBIE"
            status_color = (0, 0, 255) # ë¹¨ê°•
            
            # í…Œë‘ë¦¬ íš¨ê³¼
            cv2.rectangle(img, (0,0), (w, h), (0,0,255), 10)
            cv2.putText(img, "!!! WARNING !!!", (w//2 - 100, h//2), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,0,255), 4)
            
            # ì†Œë¦¬ ì¶œë ¥
            current_time = time.time()
            if current_time - last_beep_time > 1.0:
                winsound.Beep(1000, 500)
                last_beep_time = current_time
        else:
            # ìì„¸ëŠ” ìŠ¤ëª¸ë¹„ì¸ë° í°ì´ ì—†ìŒ (ë¹ˆì†)
            final_decision = "Pose: Smombie (No Phone)"
            status_color = (0, 165, 255) # ì£¼í™© (ì£¼ì˜)
    
    # ìƒíƒœ í…ìŠ¤íŠ¸ ì¶œë ¥
    cv2.putText(img, f"Action: {action.upper()} ({lstm_conf*100:.0f}%)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(img, f"Phone Held: {is_holding_phone}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(img, f"Status: {final_decision}", (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)

    cv2.imshow('Final Hybrid Guard', img)
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()